module trajectories;

import discretefunctions;
import discretemdp;
import std.typecons;


// Takes in incomplete trajectories and computes the complete distribution over all possible trajectories
interface Sequence_Distribution_Computer(T ...) {

    public Sequence!(Distribution!(T))[] to_traj_distr( Sequence!(T)[] trajectories, double [] weights );
}


// Takes perfectly observed trajectories and converts them to trajectory distributions
class CompleteTrajectoryToTrajectoryDistr : Sequence_Distribution_Computer!(State, Action) {

    Set!(State) state_space;
    Set!(Action) action_space;
    bool extend_terminals_to_equal_length;
    
    public this(Set!(State) state_set, Set!(Action) action_set, bool extend_terminals_to_equal_length = true) {
        this.state_space = state_set;
        this.action_space = action_set;
        this.extend_terminals_to_equal_length = extend_terminals_to_equal_length;
    }

    public Sequence!(Distribution!(State, Action))[] to_traj_distr( Sequence!(State, Action)[] trajectories, double [] weights ) {

        Sequence!(Distribution!(State, Action))[] returnval = new Sequence!(Distribution!(State, Action))[trajectories.length];

        auto full_space = state_space.cartesian_product(action_space);
        size_t max_traj_length = 0;
        foreach (t ; trajectories)
            if (t.length() > max_traj_length)
                max_traj_length = t.length();
        
        foreach(i, traj ; trajectories) {

            Sequence!(Distribution!(State, Action)) seq = new Sequence!(Distribution!(State, Action))(traj.length());
            foreach(t, timestep ; traj) {
                Distribution!(State, Action) dist = new Distribution!(State, Action)(full_space, 0.0);

            
                if (timestep[0].isTerminal() && timestep[1] is null) {
                    // In this case, we're missing the action for the terminal state
                    // fix this by making all actions equally likely
                    foreach (a ; action_space) {
                        dist[tuple(timestep[0], a[0])] = 1.0 / action_space.size();
                    }
                    
                } else {
                    dist[timestep] = 1.0;
                }

                seq[t] = tuple(dist);
            }

            if (traj[$][0].isTerminal() && extend_terminals_to_equal_length ) {

                while( seq.length() < max_traj_length) {
                    seq ~= seq[$];
                }
            }
            
            returnval[i] = seq;
        }

        return returnval;

    }

}

// convenience, since these types of trajectories are generated by so many tests
public Sequence!(Distribution!(State, Action))[] traj_to_traj_distr( Sequence!(State, Action)[] trajectories, Model m, bool extend_to_equal_lengths = true) {

    CompleteTrajectoryToTrajectoryDistr converter = new CompleteTrajectoryToTrajectoryDistr(m.S(), m.A());

    return converter.to_traj_distr(trajectories, null);
    
}

